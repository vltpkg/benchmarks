name: Registry Benchmarks
on:
  workflow_dispatch:
    inputs:
      fixtures:
        description: 'The fixtures to run the benchmarks on'
        default: '["next", "astro", "vue", "svelte", "large", "babylon"]'
      variations:
        description: 'The registry variations to run'
        default: '["registry-clean", "registry-lockfile"]'
      warmup:
        description: 'The number of warmup runs on each benchmark'
        default: '2'
      runs:
        description: 'The number of runs on each benchmark'
        default: '10'
  schedule:
    - cron: "0 0 * * *"

# Prevent multiple runs from interfering with each other
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  id-token: write
  contents: write

jobs:
  benchmark:
    name: 'Run Registry Benchmarks'
    runs-on: ubuntu-latest
    timeout-minutes: 60
    strategy:
      matrix:
        fixture: ${{ fromJson(inputs.fixtures || '["next", "astro", "vue", "svelte", "large", "babylon"]') }}
        variation: ${{ fromJson(inputs.variations || '["registry-clean", "registry-lockfile"]') }}
    env:
      BENCH_WARMUP: ${{ inputs.warmup || '2' }}
      BENCH_RUNS: ${{ inputs.runs || '10' }}
    steps:
      - uses: actions/checkout@v4
      - name: Install Node
        uses: actions/setup-node@v4
        with:
          node-version: '24'
      - name: Install & Setup Tools
        run: |
          bash ./scripts/setup.sh
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: us-east-1
      - name: Get CodeArtifact Token
        id: codeartifact
        run: |
          CODEARTIFACT_AUTH_TOKEN=$(aws codeartifact get-authorization-token \
            --domain vlt \
            --domain-owner 451504312483 \
            --region us-east-1 \
            --query authorizationToken \
            --output text)
          echo "::add-mask::$CODEARTIFACT_AUTH_TOKEN"
          echo "token=$CODEARTIFACT_AUTH_TOKEN" >> "$GITHUB_OUTPUT"
      - name: Run Registry Benchmarks
        env:
          VLT_REGISTRY_AUTH_TOKEN: ${{ secrets.VLT_REGISTRY_AUTH_TOKEN }}
          CODEARTIFACT_AUTH_TOKEN: ${{ steps.codeartifact.outputs.token }}
        run: |
          bash ./scripts/benchmark.sh ${{ matrix.fixture }} ${{ matrix.variation }}
      - name: Upload Benchmark Results
        uses: actions/upload-artifact@v4
        with:
          name: results-${{ matrix.fixture }}-${{ matrix.variation }}
          path: ./results/${{ matrix.fixture }}/${{ matrix.variation }}/
          retention-days: 7
      - name: Upload Versions Info
        uses: actions/upload-artifact@v4
        with:
          name: versions-${{ matrix.fixture }}-${{ matrix.variation }}
          path: ./results/versions.json
          retention-days: 7
  process:
    name: 'Process Results'
    runs-on: ubuntu-latest
    needs: [benchmark]
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v4
      - name: Install Node
        uses: actions/setup-node@v4
        with:
          node-version: '24'
      - name: Download Results
        uses: actions/download-artifact@v4
        with:
          path: results
          pattern: results-*
      - name: Download Versions
        uses: actions/download-artifact@v4
        with:
          path: versions-temp
          pattern: versions-*
      - name: Clean benchmarks result
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            const fixtures = [
              "next",
              "astro",
              "vue",
              "svelte",
              "large",
              "babylon"
            ];
            const variations = [
              "registry-clean",
              "registry-lockfile"
            ];

            function calculateMean(times) {
              return times.reduce((sum, time) => sum + time, 0) / times.length;
            }

            function calculateStddev(times, mean) {
              const variance = times.reduce((sum, time) => sum + Math.pow(time - mean, 2), 0) / times.length;
              return Math.sqrt(variance);
            }

            function calculateMedian(times) {
              const sorted = [...times].sort((a, b) => a - b);
              const mid = Math.floor(sorted.length / 2);
              return sorted.length % 2 === 0
                ? (sorted[mid - 1] + sorted[mid]) / 2
                : sorted[mid];
            }

            for (const fixture of fixtures) {
              for (const variation of variations) {
                const benchmarkPath = path.join('results', `results-${fixture}-${variation}`, 'benchmarks.json');

                try {
                  console.log(`Cleaning benchmark file: ${benchmarkPath}`);
                  const benchmarkData = JSON.parse(fs.readFileSync(benchmarkPath, 'utf8'));

                  if (benchmarkData.results && benchmarkData.results.length > 0) {
                    for (let i = 0; i < benchmarkData.results.length; i++) {
                      const result = benchmarkData.results[i];
                      const { times, exit_codes } = result;

                      if (times && exit_codes && times.length === exit_codes.length) {
                        const cleanTimes = times.filter((time, index) => exit_codes[index] === 0);
                        const cleanExitCodes = exit_codes.filter(code => code === 0);

                        if (cleanTimes.length > 0) {
                          const mean = calculateMean(cleanTimes);
                          const stddev = calculateStddev(cleanTimes, mean);
                          const median = calculateMedian(cleanTimes);
                          const min = Math.min(...cleanTimes);
                          const max = Math.max(...cleanTimes);

                          result.times = cleanTimes;
                          result.exit_codes = cleanExitCodes;
                          result.mean = mean;
                          result.stddev = stddev;
                          result.median = median;
                          result.min = min;
                          result.max = max;

                          console.log(`Cleaned ${fixture}-${variation} (result ${i}): ${times.length - cleanTimes.length} failed runs removed, ${cleanTimes.length} valid runs remaining`);
                        } else {
                          console.warn(`All runs failed for ${fixture}-${variation} (result ${i})`);
                          result.times = [0];
                          result.exit_codes = [1];
                          result.mean = 0;
                          result.stddev = 0;
                          result.median = 0;
                          result.min = 0;
                          result.max = 0;
                          result.user = 0;
                          result.system = 0;
                        }
                      } else {
                        console.warn(`Invalid times/exit_codes arrays for ${fixture}-${variation} (result ${i})`);
                      }
                    }

                    fs.writeFileSync(benchmarkPath, JSON.stringify(benchmarkData, null, 2));
                  } else {
                    console.warn(`No results found in ${benchmarkPath}`);
                  }
                } catch (error) {
                  console.error(`Failed to clean ${benchmarkPath}: ${error.message}`);
                }
              }
            }

            console.log('Benchmark cleaning completed');
      - name: Process Results
        run: |
          bash ./scripts/process-results.sh
      - name: Install vlt
        run: |
          npm install -g vlt@latest
      - name: Build Charts View
        run: |
          pushd app
          vlt install || true
          vlt run build
          popd
      - name: Upload Processed Results
        uses: actions/upload-artifact@v4
        with:
          name: results
          path: results/
          retention-days: 7
  deploy:
    name: 'Deploy Results'
    runs-on: ubuntu-latest
    needs: [process]
    permissions:
      contents: write
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4
      - name: Download Results
        uses: actions/download-artifact@v4
        with:
          name: results
          path: results/
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: results
          keep_files: true
